{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "DM2020-Lab1-Homework.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "db1s3M92srkH",
        "JYxm_sDYsrkI",
        "_vEbi102we3U"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3DebbieChen9/DM2020-Lab1-Homework1/blob/main/DM2020_Lab1_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db1s3M92srkH"
      },
      "source": [
        "## Student Information\n",
        "Name: **陳彥如 Debbie Chen**\n",
        "\n",
        "Student ID: **106034026**\n",
        "\n",
        "GitHub ID: 3DebbieChen9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-rWdgpzsrkI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYxm_sDYsrkI"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exJZg9pesrkJ"
      },
      "source": [
        "1. First: do the **take home** exercises in the [DM2020-Lab1-Master Repo](https://github.com/fhcalderon87/DM2020-Lab1-Master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
        "\n",
        "\n",
        "2. Second: follow the same process from the [DM2020-Lab1-Master Repo](https://github.com/fhcalderon87/DM2020-Lab1-Master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
        "    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. \n",
        "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
        "\n",
        "\n",
        "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
        "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
        "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
        "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
        "\n",
        "\n",
        "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
        "\n",
        "\n",
        "5. Fifth: It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
        "\n",
        "\n",
        "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fhcalderon87/DM2020-Lab1-Master/blob/master/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (Oct. 22th 11:59 pm, Thursday)__. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2r7wrn9srkK"
      },
      "source": [
        "### Begin Assignment Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vEbi102we3U"
      },
      "source": [
        "## Initial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLkQ6NQ4tCxd"
      },
      "source": [
        "# TEST necessary for when working with external scripts\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NX1PjlzwtUt"
      },
      "source": [
        "## First: Take home exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RyU_vALwdRH"
      },
      "source": [
        "# categories\n",
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ORjIjHTwz-4",
        "outputId": "5f3efb09-43f8-45fa-f4b1-b855ed5c6b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# obtain the documents containing the categories provided\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, \\\n",
        "                                  shuffle=True, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9TSwSklw_E4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# my functions\n",
        "import helpers.data_mining_helpers as dmh\n",
        "\n",
        "# construct dataframe from a list\n",
        "X = pd.DataFrame.from_records(dmh.format_rows(twenty_train), columns= ['text'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ssDtOcO0eXh"
      },
      "source": [
        "# add category to the dataframe\n",
        "X['category'] = twenty_train.target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArJv5hs0fwd"
      },
      "source": [
        "# add category label also\n",
        "X['category_name'] = X.category.apply(lambda t: dmh.format_labels(t, twenty_train))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K31uhFv2uN9"
      },
      "source": [
        "### ** >>> Exercise 2 (take home):** \n",
        "Experiment with other querying techniques using pandas dataframes. Refer to their [documentation](https://pandas.pydata.org/pandas-docs/stable/indexing.html) for more information. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj-zQEy-0het"
      },
      "source": [
        " #Answer here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtlDIivI3H1Z"
      },
      "source": [
        ""
      ]
    }
  ]
}